# <center>**MachineLearning - 机器学习**

## **一、概述** 
### 1、什么是机器学习？
机器学习就是把无序的数据转换成有用的信息

### 2、术语
训练集：用于训练机器学习算法的数据样本集合   
特征/属性：训练样本集的列，是独立测量得到的结果，多个特征联系到一起共同组成一个训练样本  
目标变量：机器学习算法的预测结果  

### 3、主要任务
- 分类：将实例数据划分到合适的分类中
- 回归：主要用于预测数值型数据
- 聚类：数据集合分成类似的对象组成的多个类的过程
- 密度估计：寻找描述数据统计值的过程

### 4、分类
机器学习按照模型类型分类主要可分为监督学习和无监督学习  
- 监督学习  
必须知道预测什么，即目标变量的分类信息  
分类和回归都属于监督学习，监督学习一般使用两种类型的目标变量：标称型和数值型  
标称型：结果只在有限目标集合中取值，如真与假，一般用于分类  
数值型：可以从无限的数值集合中取值，一般用于回归
- 无监督学习  
数据没有类别信息，也不会给定目标值  
聚类和密度估计都属于无监督学习，无监督学习可以减少数据特征的维度

### 5、如何选择合适的算法
（1）使用机器学习算法的目的  
（2） 需要分析或收集的数据是什么  

### 6、步骤
（1）收集数据  
（2）准备输入数据  
（3）分析输入数据  
（4）训练算法  
（5）测试算法  
（6）使用算法  

## **二、K-近邻算法**
K-近邻算法（KNN）采用测量不同特征值之间的距离方法进行分类，属于监督学习中的分类算法，结果确定  
优点：精度高、对异常值不敏感、无数据输入假定  
缺点：计算复杂度高、空间复杂度高  
使用数据范围：数值型和标称型  

### 1、工作原理
存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，只选择样本数据集中前k个最相似的数据，通常k是不大于20的整数。最后，在k个最相似数据中出现次数最多的分类，作为新数据的分类。

### 2、一般流程
（1）收集数据：可以使用任何方法  
（2）准备数据：距离计算所需要的数值，最好是结构化的数据格式  
（3）分析数据：可以使用任何方法  
（4）训练算法：此步骤不适用于K-近邻算法  
（5）测试算法：计算错误率  
（6）使用算法：首选需要输入样本数据和结构化的输出结果，然后运行K-近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理

## **三、决策树**
决策树(Decision Tree)是一种非参数的有监督学习，它能够从一系列有特征有标签的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。
优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据  
缺点：可能会产生过度匹配问题  
适用数据类型：数值型和标称型  

### 1、相关定义
- 香农熵  
集合信息的度量方式成为香农熵或者简称为熵（entropy），熵定义为信息的期望值。熵越大，则混合的数据也就越多。
- 条件熵  
条件熵H(Y|X)表示在已知随机变量 X 的条件下随机变量 Y 的不确定性。
- 信息增益  
信息增益时熵的减少或者是数据无序度的减少。计算方法为：信息增益=熵-条件熵

### 2、一般流程  
（1）收集数据：可以使用任何方法  
（2）准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化  
（3）分析数据：可以使用任何方法，构造树完成之后，应检查图形是否符合预期  
（4）训练算法：构造树的数据结构  
（5）测试算法：使用经验树计算错误率  
（6）使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好的理解数据的内在含义  

### 3、决策树构建算法
常见的决策树算法有ID3、C4.5、CART  
（1）ID3：根据信息增益来选择进行划分的最优特征，然后递归地构建决策树  

<br>

[^] **参考资料**
> **1.《Machine Learning in Action》 [美] Peter Harrington 著**



